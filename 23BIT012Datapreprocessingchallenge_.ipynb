{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPI7NNsr+47txhrR0IDl/Ip",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/P-Brundha/info/blob/main/23BIT012Datapreprocessingchallenge_.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KlKIWEnQkh0g",
        "outputId": "f1d3192f-8fa8-4cf6-e7dd-f03500e62f6c"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: pyspark in /usr/local/lib/python3.12/dist-packages (3.5.1)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.12/dist-packages (0.3.13)\n",
            "Requirement already satisfied: py4j==0.10.9.7 in /usr/local/lib/python3.12/dist-packages (from pyspark) (0.10.9.7)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.12/dist-packages (from kagglehub) (25.0)\n",
            "Requirement already satisfied: pyyaml in /usr/local/lib/python3.12/dist-packages (from kagglehub) (6.0.3)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.12/dist-packages (from kagglehub) (2.32.4)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.12/dist-packages (from kagglehub) (4.67.1)\n",
            "Requirement already satisfied: charset_normalizer<4,>=2 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.4.3)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (3.10)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2.5.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.12/dist-packages (from requests->kagglehub) (2025.10.5)\n"
          ]
        }
      ],
      "source": [
        "!pip install pyspark kagglehub"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import kagglehub\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.functions import col, mean, when, count, isnan\n",
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "\n",
        "\n",
        "# Download latest version\n",
        "path = kagglehub.dataset_download(\"carrie1/ecommerce-data\")\n",
        "\n",
        "print(\"Path to dataset files:\", path)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "J1cYInAKlDPd",
        "outputId": "d8fc1d10-ff30-4546-d3aa-1d4b891d69c4"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading from https://www.kaggle.com/api/v1/datasets/download/carrie1/ecommerce-data?dataset_version_number=1...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 7.20M/7.20M [00:00<00:00, 70.6MB/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting files...\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Path to dataset files: /root/.cache/kagglehub/datasets/carrie1/ecommerce-data/versions/1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "spark = SparkSession.builder \\\n",
        "    .appName(\"DataPreprocessingChallenge\") \\\n",
        "    .getOrCreate()\n",
        "\n",
        "print(\"✅ Spark session created successfully!\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "yRJqWkp0mepn",
        "outputId": "52ac658f-d53b-42d3-ea3b-7c9834e10e9f"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Spark session created successfully!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Read CSV file\n",
        "file_path = f\"{path}/data.csv\"  # Kaggle dataset file name\n",
        "data = spark.read.csv(file_path, header=True, inferSchema=True)\n",
        "\n",
        "print(\"✅ Dataset loaded successfully.\")\n",
        "data.printSchema()\n",
        "data.show(5)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bQkOYePZlDR9",
        "outputId": "a540c309-48a7-46fa-bbc7-cfc693b682fc"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Dataset loaded successfully.\n",
            "root\n",
            " |-- InvoiceNo: string (nullable = true)\n",
            " |-- StockCode: string (nullable = true)\n",
            " |-- Description: string (nullable = true)\n",
            " |-- Quantity: integer (nullable = true)\n",
            " |-- InvoiceDate: string (nullable = true)\n",
            " |-- UnitPrice: double (nullable = true)\n",
            " |-- CustomerID: integer (nullable = true)\n",
            " |-- Country: string (nullable = true)\n",
            "\n",
            "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
            "|InvoiceNo|StockCode|         Description|Quantity|   InvoiceDate|UnitPrice|CustomerID|       Country|\n",
            "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
            "|   536365|   85123A|WHITE HANGING HEA...|       6|12/1/2010 8:26|     2.55|     17850|United Kingdom|\n",
            "|   536365|    71053| WHITE METAL LANTERN|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
            "|   536365|   84406B|CREAM CUPID HEART...|       8|12/1/2010 8:26|     2.75|     17850|United Kingdom|\n",
            "|   536365|   84029G|KNITTED UNION FLA...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
            "|   536365|   84029E|RED WOOLLY HOTTIE...|       6|12/1/2010 8:26|     3.39|     17850|United Kingdom|\n",
            "+---------+---------+--------------------+--------+--------------+---------+----------+--------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Count missing values\n",
        "missing_counts = data.select([count(when(col(c).isNull() | isnan(c), c)).alias(c) for c in data.columns])\n",
        "print(\"🔍 Missing value count per column:\")\n",
        "missing_counts.show()\n",
        "\n",
        "# Fill missing numeric columns with mean\n",
        "numeric_cols = [c for c, t in data.dtypes if t in ['double', 'int']]\n",
        "for column in numeric_cols:\n",
        "    mean_value = data.select(mean(col(column))).collect()[0][0]\n",
        "    data = data.fillna({column: mean_value})\n",
        "\n",
        "# Fill missing categorical columns (if any)\n",
        "categorical_cols = [c for c, t in data.dtypes if t == 'string']\n",
        "for column in categorical_cols:\n",
        "    data = data.fillna({column: 'Unknown'})\n",
        "\n",
        "print(\"✅ Missing values handled.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "uACEEtPElDVl",
        "outputId": "24ecec11-e004-4892-cabc-5c5646a9a571"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🔍 Missing value count per column:\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|InvoiceNo|StockCode|Description|Quantity|InvoiceDate|UnitPrice|CustomerID|Country|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "|        0|        0|       1454|       0|          0|        0|    135080|      0|\n",
            "+---------+---------+-----------+--------+-----------+---------+----------+-------+\n",
            "\n",
            "✅ Missing values handled.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "for column in numeric_cols:\n",
        "    data = data.withColumn(column, col(column).cast(\"double\"))\n",
        "\n",
        "data.printSchema()\n",
        "print(\"✅ Data types standardized.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "18-_gzvUngBS",
        "outputId": "2090403d-2a05-4257-a6b0-f43133c359c1"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "root\n",
            " |-- InvoiceNo: string (nullable = false)\n",
            " |-- StockCode: string (nullable = false)\n",
            " |-- Description: string (nullable = false)\n",
            " |-- Quantity: double (nullable = true)\n",
            " |-- InvoiceDate: string (nullable = false)\n",
            " |-- UnitPrice: double (nullable = false)\n",
            " |-- CustomerID: double (nullable = true)\n",
            " |-- Country: string (nullable = false)\n",
            "\n",
            "✅ Data types standardized.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "before = data.count()\n",
        "data = data.dropDuplicates()\n",
        "after = data.count()\n",
        "\n",
        "print(f\"🧹 Removed {before - after} duplicate rows.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Gx1dqVRzngN1",
        "outputId": "2c05933a-9db6-4888-a74a-38d3c019811d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "🧹 Removed 5268 duplicate rows.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pyspark.ml.feature import VectorAssembler, StandardScaler\n",
        "\n",
        "# Select only numeric columns\n",
        "numeric_cols = ['Quantity', 'UnitPrice']\n",
        "\n",
        "assembler = VectorAssembler(\n",
        "    inputCols=numeric_cols,\n",
        "    outputCol=\"features\"\n",
        ")\n",
        "\n",
        "# Assemble numeric columns into feature vector\n",
        "assembled = assembler.transform(data)\n",
        "\n",
        "# Apply StandardScaler\n",
        "scaler = StandardScaler(\n",
        "    inputCol=\"features\",\n",
        "    outputCol=\"scaled_features\",\n",
        "    withMean=True,\n",
        "    withStd=True\n",
        ")\n",
        "\n",
        "scaler_model = scaler.fit(assembled)\n",
        "scaled_data = scaler_model.transform(assembled)\n",
        "\n",
        "print(\"✅ Data normalization completed.\")\n",
        "scaled_data.select(\"scaled_features\").show(5, truncate=False)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xSMQ_ZyvngRe",
        "outputId": "5cd3570d-030a-4b86-950c-c8fcd2ebd527"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Data normalization completed.\n",
            "+-------------------------------------------+\n",
            "|scaled_features                            |\n",
            "+-------------------------------------------+\n",
            "|[-0.01651999476641918,-0.034789131080195]  |\n",
            "|[-0.0393374840991838,-0.030675306390441394]|\n",
            "|[-0.0393374840991838,-0.02450456935581098] |\n",
            "|[-0.0393374840991838,-0.030675306390441394]|\n",
            "|[-0.03477398623263087,-0.04095986811482541]|\n",
            "+-------------------------------------------+\n",
            "only showing top 5 rows\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop complex vector columns before saving\n",
        "clean_data = scaled_data.drop(\"features\", \"scaled_features\")\n",
        "\n",
        "# Define output path\n",
        "output_path = \"/content/cleaned_creditcard_data.csv\"\n",
        "\n",
        "# Save as CSV\n",
        "clean_data.write.csv(output_path, header=True, mode=\"overwrite\")\n",
        "\n",
        "print(f\"✅ Cleaned dataset saved successfully at: {output_path}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ArcJUwRBn_o2",
        "outputId": "8b889f32-fcd5-4eb3-d698-79f5417eac4d"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Cleaned dataset saved successfully at: /content/cleaned_creditcard_data.csv\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(\"📊 Data Preprocessing Summary\")\n",
        "print(\"- Missing values handled (numeric: mean, categorical: 'Unknown')\")\n",
        "print(\"- Data types standardized to double\")\n",
        "print(\"- Duplicates removed\")\n",
        "print(\"- Features normalized using StandardScaler\")\n",
        "print(\"- Engineered features: Transaction_Hour, Amount_Category\")\n",
        "print(\"✅ Dataset ready for downstream analytics or ML tasks.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xsF6QNtJn_sd",
        "outputId": "4558819e-c8c1-40d4-f855-77354049b206"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📊 Data Preprocessing Summary\n",
            "- Missing values handled (numeric: mean, categorical: 'Unknown')\n",
            "- Data types standardized to double\n",
            "- Duplicates removed\n",
            "- Features normalized using StandardScaler\n",
            "- Engineered features: Transaction_Hour, Amount_Category\n",
            "✅ Dataset ready for downstream analytics or ML tasks.\n"
          ]
        }
      ]
    }
  ]
}