{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyM8cCRjHZrmj2JVtwO7kaKY",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/P-Brundha/info/blob/main/23BIT012_Realtimestreaming.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 417
        },
        "id": "bW5_6Pzcr2mp",
        "outputId": "12d2e2bb-d36c-4285-d0f4-f77fedc526b1"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "📥 Wrote new batch file: /content/input_stream/batch_5.csv  (10 rows)\n",
            "✅ 5 microbatches generated and processed.\n",
            "🛑 Streaming stopped and Spark session closed.\n",
            "📂 Processed batch files: ['/content/output_stream/batch_0.csv', '/content/output_stream/batch_1.csv', '/content/output_stream/batch_2.csv', '/content/output_stream/batch_3.csv', '/content/output_stream/batch_4.csv', '/content/output_stream/batch_5.csv', '/content/output_stream/batch_6.csv']\n",
            "\n",
            "Sample rows from last batch file:\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "   sensor_id  temperature  humidity  vibration                   timestamp  \\\n",
              "0  sensor_id         0.00      0.00       0.00                           0   \n",
              "1         s1        34.28     78.74       0.57  2025-10-16 11:11:34.743743   \n",
              "2         s1        35.73     34.37       4.44  2025-10-16 11:11:34.743789   \n",
              "3         s3        28.30     83.97       0.79  2025-10-16 11:11:34.743820   \n",
              "4         s3        40.21     63.02       4.84  2025-10-16 11:11:34.743831   \n",
              "\n",
              "   prediction                processed_at  \n",
              "0           0  2025-10-16 11:11:40.516401  \n",
              "1           0  2025-10-16 11:11:40.516401  \n",
              "2           1  2025-10-16 11:11:40.516401  \n",
              "3           0  2025-10-16 11:11:40.516401  \n",
              "4           1  2025-10-16 11:11:40.516401  "
            ],
            "text/html": [
              "\n",
              "  <div id=\"df-08b830df-4c9a-41fb-a2cf-b8168991c23d\" class=\"colab-df-container\">\n",
              "    <div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>sensor_id</th>\n",
              "      <th>temperature</th>\n",
              "      <th>humidity</th>\n",
              "      <th>vibration</th>\n",
              "      <th>timestamp</th>\n",
              "      <th>prediction</th>\n",
              "      <th>processed_at</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>sensor_id</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0.00</td>\n",
              "      <td>0</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-10-16 11:11:40.516401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>s1</td>\n",
              "      <td>34.28</td>\n",
              "      <td>78.74</td>\n",
              "      <td>0.57</td>\n",
              "      <td>2025-10-16 11:11:34.743743</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-10-16 11:11:40.516401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>s1</td>\n",
              "      <td>35.73</td>\n",
              "      <td>34.37</td>\n",
              "      <td>4.44</td>\n",
              "      <td>2025-10-16 11:11:34.743789</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-10-16 11:11:40.516401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>s3</td>\n",
              "      <td>28.30</td>\n",
              "      <td>83.97</td>\n",
              "      <td>0.79</td>\n",
              "      <td>2025-10-16 11:11:34.743820</td>\n",
              "      <td>0</td>\n",
              "      <td>2025-10-16 11:11:40.516401</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>s3</td>\n",
              "      <td>40.21</td>\n",
              "      <td>63.02</td>\n",
              "      <td>4.84</td>\n",
              "      <td>2025-10-16 11:11:34.743831</td>\n",
              "      <td>1</td>\n",
              "      <td>2025-10-16 11:11:40.516401</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>\n",
              "    <div class=\"colab-df-buttons\">\n",
              "\n",
              "  <div class=\"colab-df-container\">\n",
              "    <button class=\"colab-df-convert\" onclick=\"convertToInteractive('df-08b830df-4c9a-41fb-a2cf-b8168991c23d')\"\n",
              "            title=\"Convert this dataframe to an interactive table.\"\n",
              "            style=\"display:none;\">\n",
              "\n",
              "  <svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\" viewBox=\"0 -960 960 960\">\n",
              "    <path d=\"M120-120v-720h720v720H120Zm60-500h600v-160H180v160Zm220 220h160v-160H400v160Zm0 220h160v-160H400v160ZM180-400h160v-160H180v160Zm440 0h160v-160H620v160ZM180-180h160v-160H180v160Zm440 0h160v-160H620v160Z\"/>\n",
              "  </svg>\n",
              "    </button>\n",
              "\n",
              "  <style>\n",
              "    .colab-df-container {\n",
              "      display:flex;\n",
              "      gap: 12px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert {\n",
              "      background-color: #E8F0FE;\n",
              "      border: none;\n",
              "      border-radius: 50%;\n",
              "      cursor: pointer;\n",
              "      display: none;\n",
              "      fill: #1967D2;\n",
              "      height: 32px;\n",
              "      padding: 0 0 0 0;\n",
              "      width: 32px;\n",
              "    }\n",
              "\n",
              "    .colab-df-convert:hover {\n",
              "      background-color: #E2EBFA;\n",
              "      box-shadow: 0px 1px 2px rgba(60, 64, 67, 0.3), 0px 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "      fill: #174EA6;\n",
              "    }\n",
              "\n",
              "    .colab-df-buttons div {\n",
              "      margin-bottom: 4px;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert {\n",
              "      background-color: #3B4455;\n",
              "      fill: #D2E3FC;\n",
              "    }\n",
              "\n",
              "    [theme=dark] .colab-df-convert:hover {\n",
              "      background-color: #434B5C;\n",
              "      box-shadow: 0px 1px 3px 1px rgba(0, 0, 0, 0.15);\n",
              "      filter: drop-shadow(0px 1px 2px rgba(0, 0, 0, 0.3));\n",
              "      fill: #FFFFFF;\n",
              "    }\n",
              "  </style>\n",
              "\n",
              "    <script>\n",
              "      const buttonEl =\n",
              "        document.querySelector('#df-08b830df-4c9a-41fb-a2cf-b8168991c23d button.colab-df-convert');\n",
              "      buttonEl.style.display =\n",
              "        google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "\n",
              "      async function convertToInteractive(key) {\n",
              "        const element = document.querySelector('#df-08b830df-4c9a-41fb-a2cf-b8168991c23d');\n",
              "        const dataTable =\n",
              "          await google.colab.kernel.invokeFunction('convertToInteractive',\n",
              "                                                    [key], {});\n",
              "        if (!dataTable) return;\n",
              "\n",
              "        const docLinkHtml = 'Like what you see? Visit the ' +\n",
              "          '<a target=\"_blank\" href=https://colab.research.google.com/notebooks/data_table.ipynb>data table notebook</a>'\n",
              "          + ' to learn more about interactive tables.';\n",
              "        element.innerHTML = '';\n",
              "        dataTable['output_type'] = 'display_data';\n",
              "        await google.colab.output.renderOutput(dataTable, element);\n",
              "        const docLink = document.createElement('div');\n",
              "        docLink.innerHTML = docLinkHtml;\n",
              "        element.appendChild(docLink);\n",
              "      }\n",
              "    </script>\n",
              "  </div>\n",
              "\n",
              "\n",
              "    <div id=\"df-308dbe97-d7b0-40ea-a3bd-843502514ef7\">\n",
              "      <button class=\"colab-df-quickchart\" onclick=\"quickchart('df-308dbe97-d7b0-40ea-a3bd-843502514ef7')\"\n",
              "                title=\"Suggest charts\"\n",
              "                style=\"display:none;\">\n",
              "\n",
              "<svg xmlns=\"http://www.w3.org/2000/svg\" height=\"24px\"viewBox=\"0 0 24 24\"\n",
              "     width=\"24px\">\n",
              "    <g>\n",
              "        <path d=\"M19 3H5c-1.1 0-2 .9-2 2v14c0 1.1.9 2 2 2h14c1.1 0 2-.9 2-2V5c0-1.1-.9-2-2-2zM9 17H7v-7h2v7zm4 0h-2V7h2v10zm4 0h-2v-4h2v4z\"/>\n",
              "    </g>\n",
              "</svg>\n",
              "      </button>\n",
              "\n",
              "<style>\n",
              "  .colab-df-quickchart {\n",
              "      --bg-color: #E8F0FE;\n",
              "      --fill-color: #1967D2;\n",
              "      --hover-bg-color: #E2EBFA;\n",
              "      --hover-fill-color: #174EA6;\n",
              "      --disabled-fill-color: #AAA;\n",
              "      --disabled-bg-color: #DDD;\n",
              "  }\n",
              "\n",
              "  [theme=dark] .colab-df-quickchart {\n",
              "      --bg-color: #3B4455;\n",
              "      --fill-color: #D2E3FC;\n",
              "      --hover-bg-color: #434B5C;\n",
              "      --hover-fill-color: #FFFFFF;\n",
              "      --disabled-bg-color: #3B4455;\n",
              "      --disabled-fill-color: #666;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart {\n",
              "    background-color: var(--bg-color);\n",
              "    border: none;\n",
              "    border-radius: 50%;\n",
              "    cursor: pointer;\n",
              "    display: none;\n",
              "    fill: var(--fill-color);\n",
              "    height: 32px;\n",
              "    padding: 0;\n",
              "    width: 32px;\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart:hover {\n",
              "    background-color: var(--hover-bg-color);\n",
              "    box-shadow: 0 1px 2px rgba(60, 64, 67, 0.3), 0 1px 3px 1px rgba(60, 64, 67, 0.15);\n",
              "    fill: var(--button-hover-fill-color);\n",
              "  }\n",
              "\n",
              "  .colab-df-quickchart-complete:disabled,\n",
              "  .colab-df-quickchart-complete:disabled:hover {\n",
              "    background-color: var(--disabled-bg-color);\n",
              "    fill: var(--disabled-fill-color);\n",
              "    box-shadow: none;\n",
              "  }\n",
              "\n",
              "  .colab-df-spinner {\n",
              "    border: 2px solid var(--fill-color);\n",
              "    border-color: transparent;\n",
              "    border-bottom-color: var(--fill-color);\n",
              "    animation:\n",
              "      spin 1s steps(1) infinite;\n",
              "  }\n",
              "\n",
              "  @keyframes spin {\n",
              "    0% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "      border-left-color: var(--fill-color);\n",
              "    }\n",
              "    20% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    30% {\n",
              "      border-color: transparent;\n",
              "      border-left-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    40% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-top-color: var(--fill-color);\n",
              "    }\n",
              "    60% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "    }\n",
              "    80% {\n",
              "      border-color: transparent;\n",
              "      border-right-color: var(--fill-color);\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "    90% {\n",
              "      border-color: transparent;\n",
              "      border-bottom-color: var(--fill-color);\n",
              "    }\n",
              "  }\n",
              "</style>\n",
              "\n",
              "      <script>\n",
              "        async function quickchart(key) {\n",
              "          const quickchartButtonEl =\n",
              "            document.querySelector('#' + key + ' button');\n",
              "          quickchartButtonEl.disabled = true;  // To prevent multiple clicks.\n",
              "          quickchartButtonEl.classList.add('colab-df-spinner');\n",
              "          try {\n",
              "            const charts = await google.colab.kernel.invokeFunction(\n",
              "                'suggestCharts', [key], {});\n",
              "          } catch (error) {\n",
              "            console.error('Error during call to suggestCharts:', error);\n",
              "          }\n",
              "          quickchartButtonEl.classList.remove('colab-df-spinner');\n",
              "          quickchartButtonEl.classList.add('colab-df-quickchart-complete');\n",
              "        }\n",
              "        (() => {\n",
              "          let quickchartButtonEl =\n",
              "            document.querySelector('#df-308dbe97-d7b0-40ea-a3bd-843502514ef7 button');\n",
              "          quickchartButtonEl.style.display =\n",
              "            google.colab.kernel.accessAllowed ? 'block' : 'none';\n",
              "        })();\n",
              "      </script>\n",
              "    </div>\n",
              "\n",
              "    </div>\n",
              "  </div>\n"
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "dataframe",
              "summary": "{\n  \"name\": \"    display(sample\",\n  \"rows\": 5,\n  \"fields\": [\n    {\n      \"column\": \"sensor_id\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 3,\n        \"samples\": [\n          \"sensor_id\",\n          \"s1\",\n          \"s3\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"temperature\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 16.06181278685566,\n        \"min\": 0.0,\n        \"max\": 40.21,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          34.28,\n          40.21,\n          35.73\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"humidity\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 34.904741081979104,\n        \"min\": 0.0,\n        \"max\": 83.97,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          78.74,\n          63.02,\n          34.37\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"vibration\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 2.3155064240895555,\n        \"min\": 0.0,\n        \"max\": 4.84,\n        \"num_unique_values\": 5,\n        \"samples\": [\n          0.57,\n          4.84,\n          4.44\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"timestamp\",\n      \"properties\": {\n        \"dtype\": \"string\",\n        \"num_unique_values\": 5,\n        \"samples\": [\n          \"2025-10-16 11:11:34.743743\",\n          \"2025-10-16 11:11:34.743831\",\n          \"2025-10-16 11:11:34.743789\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"prediction\",\n      \"properties\": {\n        \"dtype\": \"number\",\n        \"std\": 0,\n        \"min\": 0,\n        \"max\": 1,\n        \"num_unique_values\": 2,\n        \"samples\": [\n          1,\n          0\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    },\n    {\n      \"column\": \"processed_at\",\n      \"properties\": {\n        \"dtype\": \"object\",\n        \"num_unique_values\": 1,\n        \"samples\": [\n          \"2025-10-16 11:11:40.516401\"\n        ],\n        \"semantic_type\": \"\",\n        \"description\": \"\"\n      }\n    }\n  ]\n}"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# ============================================================\n",
        "# Install dependencies (run once in Colab)\n",
        "# ============================================================\n",
        "!pip install -q pyspark scikit-learn joblib pandas\n",
        "\n",
        "# ============================================================\n",
        "# Imports\n",
        "# ============================================================\n",
        "import os, random, time, glob\n",
        "import pandas as pd\n",
        "from datetime import datetime\n",
        "from joblib import dump, load\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "from pyspark.sql import SparkSession\n",
        "from pyspark.sql.types import StructType, StructField, StringType, DoubleType, TimestampType\n",
        "\n",
        "# ============================================================\n",
        "# 1) Train model and print Train/Test scores (so output matches)\n",
        "# ============================================================\n",
        "def generate_row():\n",
        "    temp = random.uniform(20, 45)\n",
        "    hum = random.uniform(20, 90)\n",
        "    vib = random.uniform(0, 6)\n",
        "    label = 1 if (vib > 4.0 and temp > 35) else 0\n",
        "    return [temp, hum, vib, label]\n",
        "\n",
        "rows = [generate_row() for _ in range(5000)]\n",
        "df = pd.DataFrame(rows, columns=[\"temperature\", \"humidity\", \"vibration\", \"label\"])\n",
        "\n",
        "X = df[[\"temperature\", \"humidity\", \"vibration\"]]\n",
        "y = df[\"label\"]\n",
        "\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "clf = RandomForestClassifier(n_estimators=30, random_state=42)\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "train_score = clf.score(X_train, y_train)\n",
        "test_score = clf.score(X_test, y_test)\n",
        "\n",
        "MODEL_PATH = \"/content/sensor_rf_model.joblib\"\n",
        "dump(clf, MODEL_PATH)\n",
        "\n",
        "print(\"✅ Model training completed.\")\n",
        "print(f\"Train score: {train_score:.4f}\")\n",
        "print(f\"Test score:  {test_score:.4f}\")\n",
        "print(\"Saved model to:\", MODEL_PATH)\n",
        "\n",
        "# ============================================================\n",
        "# 2) Prepare streaming directories and an initial microbatch\n",
        "# ============================================================\n",
        "input_dir  = \"/content/input_stream\"\n",
        "output_dir = \"/content/output_stream\"\n",
        "chkpt_dir  = \"/content/stream_checkpoints\"\n",
        "\n",
        "for d in (input_dir, output_dir, chkpt_dir):\n",
        "    os.makedirs(d, exist_ok=True)\n",
        "\n",
        "def gen_sensor_record():\n",
        "    return {\n",
        "        \"sensor_id\": random.choice([\"s1\",\"s2\",\"s3\"]),\n",
        "        \"temperature\": round(random.uniform(20,45),2),\n",
        "        \"humidity\": round(random.uniform(20,90),2),\n",
        "        \"vibration\": round(random.uniform(0,6),2),\n",
        "        \"timestamp\": pd.Timestamp.now()\n",
        "    }\n",
        "\n",
        "# initial microbatch file so Spark has something to pick up first\n",
        "initial_batch = pd.DataFrame([gen_sensor_record() for _ in range(20)])\n",
        "initial_path = os.path.join(input_dir, \"initial_batch.csv\")\n",
        "initial_batch.to_csv(initial_path, index=False)\n",
        "print(\"📥 Wrote initial microbatch:\", initial_path)\n",
        "\n",
        "# ============================================================\n",
        "# 3) Start Spark Structured Streaming\n",
        "# ============================================================\n",
        "spark = SparkSession.builder.appName(\"StreamingSensorML\").master(\"local[*]\").getOrCreate()\n",
        "spark.sparkContext.setLogLevel(\"WARN\")\n",
        "\n",
        "schema = StructType([\n",
        "    StructField(\"sensor_id\", StringType(), True),\n",
        "    StructField(\"temperature\", DoubleType(), True),\n",
        "    StructField(\"humidity\", DoubleType(), True),\n",
        "    StructField(\"vibration\", DoubleType(), True),\n",
        "    StructField(\"timestamp\", TimestampType(), True)\n",
        "])\n",
        "\n",
        "# safe microbatch handler\n",
        "def handle_microbatch(batch_df, batch_id):\n",
        "    # Avoid heavy collect when empty; using rdd.isEmpty() is efficient for small batches\n",
        "    try:\n",
        "        if batch_df.rdd.isEmpty():\n",
        "            print(f\"[microbatch {batch_id}] empty, skipping.\")\n",
        "            return\n",
        "    except Exception as e:\n",
        "        # fallback to count() if rdd.isEmpty() not available\n",
        "        if batch_df.count() == 0:\n",
        "            print(f\"[microbatch {batch_id}] empty (count==0), skipping.\")\n",
        "            return\n",
        "\n",
        "    # Convert to pandas (small microbatches expected)\n",
        "    pdf = batch_df.toPandas().fillna(0)\n",
        "    model = load(MODEL_PATH)\n",
        "    preds = model.predict(pdf[[\"temperature\", \"humidity\", \"vibration\"]])\n",
        "    pdf[\"prediction\"] = preds\n",
        "    pdf[\"processed_at\"] = pd.Timestamp.now()\n",
        "\n",
        "    # Print a compact sample like your friend's output\n",
        "    print(f\"\\n=== Microbatch {batch_id} (rows={len(pdf)}) ===\")\n",
        "    print(pdf.head(10).to_string(index=False))\n",
        "\n",
        "    # Save per-microbatch output\n",
        "    out_path = os.path.join(output_dir, f\"batch_{batch_id}.csv\")\n",
        "    pdf.to_csv(out_path, index=False)\n",
        "    print(f\"Wrote {os.path.basename(out_path)} with {len(pdf)} rows\")\n",
        "\n",
        "# Build streaming DataFrame and query\n",
        "stream_df = (spark.readStream\n",
        "             .schema(schema)\n",
        "             .option(\"maxFilesPerTrigger\", 1)\n",
        "             .csv(input_dir))\n",
        "\n",
        "query = (stream_df.writeStream\n",
        "         .outputMode(\"append\")\n",
        "         .foreachBatch(handle_microbatch)\n",
        "         .option(\"checkpointLocation\", chkpt_dir)\n",
        "         .start())\n",
        "\n",
        "print(\"⏳ Spark streaming started. Waiting for microbatches...\")\n",
        "\n",
        "# ============================================================\n",
        "# 4) Simulate microbatches (generate 5 files) — prints similar lines\n",
        "# ============================================================\n",
        "from IPython.display import clear_output\n",
        "\n",
        "def simulate_and_write(batch_idx, nrows=10):\n",
        "    rows = [gen_sensor_record() for _ in range(nrows)]\n",
        "    df_new = pd.DataFrame(rows)\n",
        "    path = os.path.join(input_dir, f\"batch_{batch_idx}.csv\")\n",
        "    df_new.to_csv(path, index=False)\n",
        "    clear_output(wait=True)\n",
        "    print(f\"📥 Wrote new batch file: {path}  ({len(df_new)} rows)\")\n",
        "\n",
        "NUM_BATCHES = 5\n",
        "for i in range(1, NUM_BATCHES+1):\n",
        "    simulate_and_write(i, nrows=10)\n",
        "    # small sleep so Spark processes one file per microbatch\n",
        "    time.sleep(2)\n",
        "\n",
        "print(f\"✅ {NUM_BATCHES} microbatches generated and processed.\")\n",
        "\n",
        "# ============================================================\n",
        "# 5) Wait for streaming to process files (polling) then stop gracefully\n",
        "#    We wait until we see at least NUM_BATCHES output files or timeout.\n",
        "# ============================================================\n",
        "def wait_for_outputs(expected, timeout_sec=30):\n",
        "    start = time.time()\n",
        "    while time.time() - start < timeout_sec:\n",
        "        files = glob.glob(os.path.join(output_dir, \"batch_*.csv\"))\n",
        "        if len(files) >= expected:\n",
        "            return sorted(files)\n",
        "        time.sleep(1)\n",
        "    return sorted(files)\n",
        "\n",
        "# Wait up to 30s for expected number of processed batch files\n",
        "processed_files = wait_for_outputs(NUM_BATCHES, timeout_sec=30)\n",
        "\n",
        "# Give a tiny extra delay to ensure no mid-processing stop\n",
        "time.sleep(2)\n",
        "\n",
        "# Stop query & Spark gracefully\n",
        "if query.isActive:\n",
        "    query.stop()\n",
        "spark.stop()\n",
        "print(\"🛑 Streaming stopped and Spark session closed.\")\n",
        "\n",
        "# ============================================================\n",
        "# 6) Show processed batch files & sample (matching your friend's final prints)\n",
        "# ============================================================\n",
        "processed_files = sorted(glob.glob(os.path.join(output_dir, \"batch_*.csv\")))\n",
        "print(\"📂 Processed batch files:\", processed_files)\n",
        "if processed_files:\n",
        "    sample = pd.read_csv(processed_files[-1])\n",
        "    print(\"\\nSample rows from last batch file:\")\n",
        "    display(sample.head())\n"
      ]
    }
  ]
}