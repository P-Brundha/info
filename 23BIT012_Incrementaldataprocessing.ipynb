{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOzFBujQYyRp2e+g7TJJcbL",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/P-Brundha/info/blob/main/23BIT012_Incrementaldataprocessing.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SnDcEXovk8j",
        "outputId": "fd6712c2-d9c4-4aa2-f0d8-7508c76035ad"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "✅ Base dataset created and stored at: /content/customers_base.csv\n",
            "   cust_id  txn_amount  age  loyalty\n",
            "0        1      212.33   28       81\n",
            "1        2      142.28   30       45\n",
            "2        3      455.66   43       46\n",
            "3        4      186.14   31       98\n",
            "4        5      433.72   65       85\n",
            "\n",
            "📘 Initial training complete.\n",
            "🔹 Model test accuracy: -3.335950266043837e+22\n",
            "💾 Model saved successfully as /content/regressor_v1.joblib\n",
            "📄 Event file generated: cdc_event_1.csv\n",
            "📄 Event file generated: cdc_event_2.csv\n",
            "📄 Event file generated: cdc_event_3.csv\n",
            "\n",
            "🌀 Processing cdc_event_1.csv\n",
            "🆕 Inserted cust_id 101.0\n",
            "✅ Model updated with cdc_event_1.csv\n",
            "\n",
            "🌀 Processing cdc_event_2.csv\n",
            "♻️ Updated cust_id 8.0\n",
            "✅ Model updated with cdc_event_2.csv\n",
            "\n",
            "🌀 Processing cdc_event_3.csv\n",
            "❌ Removed cust_id 15.0\n",
            "✅ Model updated with cdc_event_3.csv\n",
            "\n",
            "🚀 Incremental learning process completed.\n",
            "📂 Updated dataset saved at: /content/customers_updated.csv\n",
            "🧠 Updated model saved at: /content/regressor_v2.joblib\n",
            "\n",
            "📊 Final Dataset (last 10 entries):\n",
            "     cust_id  txn_amount   age  loyalty\n",
            "91      92.0      248.18  50.0     54.0\n",
            "92      93.0      110.08  58.0     21.0\n",
            "93      94.0      219.39  55.0     13.0\n",
            "94      95.0      132.96  62.0      5.0\n",
            "95      96.0      289.22  38.0     71.0\n",
            "96      97.0      436.57  63.0     44.0\n",
            "97      98.0      481.62  33.0      5.0\n",
            "98      99.0       83.19  23.0     50.0\n",
            "99     100.0      403.67  59.0     98.0\n",
            "100    101.0      220.00  32.0     55.0\n",
            "\n",
            "⚙️ Model coefficients: [-9.38299985e+10  6.92743609e+10]\n"
          ]
        }
      ],
      "source": [
        "# ============================================================\n",
        "# 🔁 Change Data Capture (CDC) + Incremental Learning Pipeline\n",
        "# ============================================================\n",
        "\n",
        "!pip install -q pandas scikit-learn joblib\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 1️⃣ Step 1: Create Initial Dataset\n",
        "# ------------------------------------------------------------\n",
        "import pandas as pd\n",
        "import random\n",
        "\n",
        "# Generate synthetic customer data\n",
        "records = 100\n",
        "dataset = pd.DataFrame({\n",
        "    \"cust_id\": range(1, records + 1),\n",
        "    \"txn_amount\": [round(random.uniform(10, 500), 2) for _ in range(records)],\n",
        "    \"age\": [random.randint(18, 70) for _ in range(records)],\n",
        "    \"loyalty\": [random.randint(0, 100) for _ in range(records)]\n",
        "})\n",
        "\n",
        "base_file = \"/content/customers_base.csv\"\n",
        "dataset.to_csv(base_file, index=False)\n",
        "print(\"✅ Base dataset created and stored at:\", base_file)\n",
        "print(dataset.head())\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 2️⃣ Step 2: Train Initial Incremental Model\n",
        "# ------------------------------------------------------------\n",
        "from sklearn.linear_model import SGDRegressor\n",
        "from sklearn.model_selection import train_test_split\n",
        "from joblib import dump, load\n",
        "\n",
        "# Split features and label\n",
        "X = dataset[[\"age\", \"loyalty\"]]\n",
        "y = dataset[\"txn_amount\"]\n",
        "\n",
        "# Train-test split\n",
        "X_train, X_test, y_train, y_test = train_test_split(\n",
        "    X, y, test_size=0.2, random_state=10\n",
        ")\n",
        "\n",
        "# Initialize and train incremental model\n",
        "regressor = SGDRegressor(max_iter=1000, tol=1e-3, random_state=10)\n",
        "regressor.partial_fit(X_train, y_train)\n",
        "\n",
        "print(\"\\n📘 Initial training complete.\")\n",
        "print(\"🔹 Model test accuracy:\", round(regressor.score(X_test, y_test), 4))\n",
        "\n",
        "# Save the model\n",
        "dump(regressor, \"/content/regressor_v1.joblib\")\n",
        "print(\"💾 Model saved successfully as /content/regressor_v1.joblib\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 3️⃣ Step 3: Simulate CDC Events (Insert, Update, Delete)\n",
        "# ------------------------------------------------------------\n",
        "import os\n",
        "\n",
        "cdc_path = \"/content/cdc_updates\"\n",
        "os.makedirs(cdc_path, exist_ok=True)\n",
        "\n",
        "# Create CDC event data\n",
        "cdc_events = [\n",
        "    {\"cust_id\": 101, \"txn_amount\": 220.0, \"age\": 32, \"loyalty\": 55},  # new insert\n",
        "    {\"cust_id\": 8, \"txn_amount\": 410.0, \"age\": 28, \"loyalty\": 65},   # update existing\n",
        "    {\"cust_id\": 15, \"txn_amount\": 0.0, \"age\": 45, \"loyalty\": 12},    # delete record\n",
        "]\n",
        "\n",
        "# Save each CDC event as a separate file\n",
        "for idx, ev in enumerate(cdc_events, start=1):\n",
        "    pd.DataFrame([ev]).to_csv(f\"{cdc_path}/cdc_event_{idx}.csv\", index=False)\n",
        "    print(f\"📄 Event file generated: cdc_event_{idx}.csv\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 4️⃣ Step 4: Apply CDC Changes and Retrain Model Incrementally\n",
        "# ------------------------------------------------------------\n",
        "import glob\n",
        "\n",
        "# Reload dataset and model\n",
        "data = pd.read_csv(base_file)\n",
        "model = load(\"/content/regressor_v1.joblib\")\n",
        "\n",
        "# Process CDC files sequentially\n",
        "cdc_files = sorted(glob.glob(f\"{cdc_path}/*.csv\"))\n",
        "\n",
        "for event_file in cdc_files:\n",
        "    cdc_data = pd.read_csv(event_file)\n",
        "    print(f\"\\n🌀 Processing {os.path.basename(event_file)}\")\n",
        "\n",
        "    for _, rec in cdc_data.iterrows():\n",
        "        # DELETE operation\n",
        "        if rec[\"txn_amount\"] == 0:\n",
        "            data = data[data.cust_id != rec[\"cust_id\"]]\n",
        "            print(f\"❌ Removed cust_id {rec['cust_id']}\")\n",
        "        # UPDATE operation\n",
        "        elif rec[\"cust_id\"] in data[\"cust_id\"].values:\n",
        "            data.loc[data.cust_id == rec[\"cust_id\"], [\"txn_amount\",\"age\",\"loyalty\"]] = \\\n",
        "                rec[[\"txn_amount\",\"age\",\"loyalty\"]].values\n",
        "            print(f\"♻️ Updated cust_id {rec['cust_id']}\")\n",
        "        # INSERT operation\n",
        "        else:\n",
        "            data = pd.concat([data, pd.DataFrame([rec])], ignore_index=True)\n",
        "            print(f\"🆕 Inserted cust_id {rec['cust_id']}\")\n",
        "\n",
        "    # Incrementally retrain model\n",
        "    X_new = cdc_data[[\"age\", \"loyalty\"]]\n",
        "    y_new = cdc_data[\"txn_amount\"]\n",
        "    model.partial_fit(X_new, y_new)\n",
        "    print(f\"✅ Model updated with {os.path.basename(event_file)}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 5️⃣ Step 5: Save Updated Model & Dataset\n",
        "# ------------------------------------------------------------\n",
        "updated_data_file = \"/content/customers_updated.csv\"\n",
        "updated_model_file = \"/content/regressor_v2.joblib\"\n",
        "\n",
        "data.to_csv(updated_data_file, index=False)\n",
        "dump(model, updated_model_file)\n",
        "\n",
        "print(\"\\n🚀 Incremental learning process completed.\")\n",
        "print(f\"📂 Updated dataset saved at: {updated_data_file}\")\n",
        "print(f\"🧠 Updated model saved at: {updated_model_file}\")\n",
        "\n",
        "# ------------------------------------------------------------\n",
        "# 6️⃣ Step 6: Display Final Output Summary\n",
        "# ------------------------------------------------------------\n",
        "print(\"\\n📊 Final Dataset (last 10 entries):\")\n",
        "print(data.tail(10))\n",
        "\n",
        "final_model = load(updated_model_file)\n",
        "print(\"\\n⚙️ Model coefficients:\", final_model.coef_)\n"
      ]
    }
  ]
}